{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "independent-overall",
   "metadata": {},
   "source": [
    "## 9. Alternating Least Square (ALS) with Spark ML for recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-seventh",
   "metadata": {},
   "source": [
    "#### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neither-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate() \n",
    "sc = spark.sparkContext\n",
    "\n",
    "# read json files with Spark\n",
    "#reference: https://spark.apache.org/docs/latest/sql-data-sources-json.html\n",
    "businesspath = \"yelp_academic_dataset_business.json\"\n",
    "businessdf = spark.read.json(businesspath)\n",
    "userpath=\"yelp_academic_dataset_user.json\"\n",
    "userdf = spark.read.json(userpath)\n",
    "reviewpath=\"yelp_academic_dataset_review.json\"\n",
    "reviewdf=spark.read.json(reviewpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-frequency",
   "metadata": {},
   "source": [
    "### Step1: Combine 3 data files & Reduce the dimension of business-user-stars matrix\n",
    "##### The goal of improving the ALS performance is to make the matrix less sparse \n",
    "      The steps of downsample:\n",
    "      (1)Choose the business which have reviews > 30\n",
    "      (2)choose the user whose giving reviews > 10\n",
    "      (3)choose the city which have the most reviews (Las Vegas)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phantom-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "businessdf = businessdf.select('business_id','review_count','state','city').\\\n",
    "                    where(fn.col('review_count')>=30)\n",
    "userdf = userdf.select('user_id','review_count').where(fn.col('review_count')>=10)\n",
    "\n",
    "Join_df = businessdf.select('business_id','city','state').join(reviewdf, on='business_id')\n",
    "\n",
    "Join_df = userdf.select('user_id').join(Join_df, on='user_id')\\\n",
    "                        .select('business_id','user_id','stars','city','state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "transsexual-practitioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     city|city_count|\n",
      "+---------+----------+\n",
      "|Las Vegas|   1651915|\n",
      "+---------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Join_df.groupBy(fn.col(\"city\")).agg(fn.count(\"city\").alias('city_count')).orderBy(\"City_Count\",ascending=False).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affected-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+---------+\n",
      "|         business_id|             user_id|stars|     city|\n",
      "+--------------------+--------------------+-----+---------+\n",
      "|RhEvP5flF6KoPriMH...|-3bsS2i9xqjNnIA1f...|  4.0|Las Vegas|\n",
      "|q3dJQtwZQrrurNT-1...|-3bsS2i9xqjNnIA1f...|  1.0|Las Vegas|\n",
      "|DYuOxkW4DtlJsTHdx...|-3i9bhfvrM3F1wsC9...|  3.0|Las Vegas|\n",
      "|939j88ceB05Te3D7k...|-3i9bhfvrM3F1wsC9...|  4.0|Las Vegas|\n",
      "|BLIJ-p5wYuAhw6Pp6...|-3i9bhfvrM3F1wsC9...|  3.0|Las Vegas|\n",
      "+--------------------+--------------------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Join_df = Join_df.select('business_id','user_id','stars','city').\\\n",
    "                  where(fn.col('city')=='Las Vegas').\\\n",
    "                  select('business_id','user_id','stars','city')\n",
    "Join_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-expert",
   "metadata": {},
   "source": [
    "##### Check the matrix‘s sparsity after adding three conditions: 99.96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "threaded-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings matrix is  99.96% sparse.\n",
      "CPU times: user 16.1 ms, sys: 10.8 ms, total: 27 ms\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_mat_sparsity(df):\n",
    "    # count the total number of ratings in the dataset\n",
    "    count_nonzero = df.select(\"stars\").count()\n",
    "    \n",
    "    # count the number of distinct user_id and distinct business_id\n",
    "    total_elements = df.select(\"user_id\").distinct().count()*df.select(\"business_id\").distinct().count()\n",
    "    \n",
    "    # Divide the numerator by the denominator\n",
    "    sparsity = (1.0-(count_nonzero*1.0)/total_elements)*100\n",
    "    print(\"The ratings matrix is \", \"%.2f\" % sparsity + \"% sparse.\")\n",
    "    \n",
    "get_mat_sparsity(Join_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-christian",
   "metadata": {},
   "source": [
    "### Step2 Build ALS model\n",
    "#### 1. Split train and test\n",
    "     The ratio of training and test data is 8:2\n",
    "#### 2. ALS model require the id to be integer.\n",
    "     Use window to give each business and uers id one unique integer\n",
    "#### 3.  Model paramter Explaination： \n",
    "     (1)implicitPrefs=False: Because this is an explicit problem without any other potential information when building model. \n",
    "     (2)maxIter: Max iterations which tell spark how many times to alternate between U and P when minimizing the error\n",
    "     (3)regParam:specifies the regularization parameter in ALS, to prevent ALS from overfitting to the data\n",
    "     (4)coldStartStrategy='drop',nonnegative = True: avoid return NaN and negative predictions.\n",
    "#### 4. Add param_grid and cross validation\n",
    "     Fine-tuning for the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "restricted-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 3 µs, total: 7 µs\n",
      "Wall time: 13.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ALS_df=Join_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-seventh",
   "metadata": {},
   "source": [
    "#### 1. Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aware-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.2 ms, sys: 0 ns, total: 7.2 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql import window\n",
    "\n",
    "w = window.Window().orderBy(fn.lit('A'))\n",
    "user_id_idx = ALS_df.select('user_id').distinct().withColumn('user_idx', fn.row_number().over(w))\n",
    "business_id_idx = ALS_df.select('business_id').distinct().withColumn('business_idx', fn.row_number().over(w))\n",
    "\n",
    "ALS_df = ALS_df.join(user_id_idx, on='user_id') \\\n",
    "    .join(business_id_idx, on='business_id') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-limitation",
   "metadata": {},
   "source": [
    "#### 2. ALS model require the id to be integer.\n",
    "     Give each user_id and business_id one unique integer to replace object type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "offshore-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             user_id|user_idx|\n",
      "+--------------------+--------+\n",
      "|-3bsS2i9xqjNnIA1f...|       1|\n",
      "|-3i9bhfvrM3F1wsC9...|       2|\n",
      "|-47g7LR58tpHlm7Bm...|       3|\n",
      "|-4xyc3OgPwrLshmqH...|       4|\n",
      "|-8_yETBp70WiqqN-A...|       5|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_id_idx.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "digital-physiology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|         business_id|business_idx|\n",
      "+--------------------+------------+\n",
      "|--9e1ONYQuAa-CB_R...|           1|\n",
      "|35X1ZV9tSEqB__yJE...|           2|\n",
      "|_ixV2SWDy7w8jzEAH...|           3|\n",
      "|oeRLD870Z76FD1OYW...|           4|\n",
      "|OGQ_6nIn4QQL2U6t0...|           5|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business_id_idx.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structural-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+---------+--------+------------+\n",
      "|         business_id|             user_id|stars|     city|user_idx|business_idx|\n",
      "+--------------------+--------------------+-----+---------+--------+------------+\n",
      "|--9e1ONYQuAa-CB_R...|0y8ORuC2X1i1UF6SG...|  5.0|Las Vegas|      56|           1|\n",
      "|--9e1ONYQuAa-CB_R...|3qz_dfwbFwTQeDRzy...|  5.0|Las Vegas|     156|           1|\n",
      "|--9e1ONYQuAa-CB_R...|9spixZHaqC1JeN1ld...|  2.0|Las Vegas|     320|           1|\n",
      "|--9e1ONYQuAa-CB_R...|A4GnBOU7ZCTcoQK4e...|  5.0|Las Vegas|     330|           1|\n",
      "|--9e1ONYQuAa-CB_R...|FtUDjNLhVjlIoeFKm...|  4.0|Las Vegas|     487|           1|\n",
      "|--9e1ONYQuAa-CB_R...|H0tfWQsGjEBuhXD4W...|  5.0|Las Vegas|     519|           1|\n",
      "|--9e1ONYQuAa-CB_R...|R0KVWeN9xR-F6j4z5...|  4.0|Las Vegas|     819|           1|\n",
      "|--9e1ONYQuAa-CB_R...|XZaCs-Gs0SXdZgfG3...|  4.0|Las Vegas|     968|           1|\n",
      "|--9e1ONYQuAa-CB_R...|n9DJHwgYflQ_ms8gB...|  3.0|Las Vegas|    1415|           1|\n",
      "|--9e1ONYQuAa-CB_R...|ucXjnxiEKLUOEktHF...|  5.0|Las Vegas|    1592|           1|\n",
      "|--9e1ONYQuAa-CB_R...|1rlB-SWvDU5TnDnym...|  5.0|Las Vegas|    1814|           1|\n",
      "|--9e1ONYQuAa-CB_R...|KGcyC9KXloxW_6YMG...|  4.0|Las Vegas|    2293|           1|\n",
      "|--9e1ONYQuAa-CB_R...|MFaazTdvfJ_aa6coa...|  5.0|Las Vegas|    2350|           1|\n",
      "|--9e1ONYQuAa-CB_R...|jHHRH62tCYNZnh85u...|  4.0|Las Vegas|    3035|           1|\n",
      "|--9e1ONYQuAa-CB_R...|oqTZC9WriodTCby6j...|  3.0|Las Vegas|    3192|           1|\n",
      "|--9e1ONYQuAa-CB_R...|TMqFvYbWqs8BnjLsE...|  5.0|Las Vegas|    4311|           1|\n",
      "|--9e1ONYQuAa-CB_R...|jNG2_tjNKiUaBXsbd...|  5.0|Las Vegas|    4777|           1|\n",
      "|--9e1ONYQuAa-CB_R...|mwuoYvFFchnNKaC1G...|  2.0|Las Vegas|    4868|           1|\n",
      "|--9e1ONYQuAa-CB_R...|qoffZ865qwpYJ9ZTc...|  5.0|Las Vegas|    4983|           1|\n",
      "|--9e1ONYQuAa-CB_R...|96aWRa-gy1RrsrFQU...|  2.0|Las Vegas|    5501|           1|\n",
      "+--------------------+--------------------+-----+---------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ALS_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-metro",
   "metadata": {},
   "source": [
    "##### ALS model only need three inputs: user_id/business_id/ratings, so we select the columns needed as ALS_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "angry-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----+\n",
      "|user_idx|business_idx|stars|\n",
      "+--------+------------+-----+\n",
      "|      56|           1|  5.0|\n",
      "|     156|           1|  5.0|\n",
      "|     320|           1|  2.0|\n",
      "|     330|           1|  5.0|\n",
      "|     487|           1|  4.0|\n",
      "+--------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 17.5 ms, sys: 5.07 ms, total: 22.6 ms\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ALS_df1 = ALS_df.select(fn.col('user_idx'),fn.col('business_idx'),'stars')\n",
    "ALS_df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_idx: integer (nullable = true)\n",
      " |-- business_idx: integer (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ALS_df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-dancing",
   "metadata": {},
   "source": [
    "#### 3.  Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "geographic-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root_Mean_Square error = 1.732490325709468\n",
      "CPU times: user 55.6 ms, sys: 41.1 ms, total: 96.6 ms\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "\n",
    "# set the value of seed\n",
    "(training, test) = ALS_df1.randomSplit([0.8,0.2],seed=2021)\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter = 10, regParam=0.01,implicitPrefs=False,\n",
    "          userCol='user_idx',itemCol='business_idx',ratingCol='stars',\n",
    "          coldStartStrategy='drop',nonnegative = True)\n",
    "#(1) maxIter is the maximum number of iterations to run (defaults to 10): \n",
    "#.   alternating fix the matrix U(user_matrix) and P(business_matrix) to minimzie the the least-squares/minimize the error\n",
    "#(2) regParam specifies the regularization parameter in ALS (defaults to 1.0)\n",
    "#(3)[coldStartStrategy='drop' and nonnegative = True] to avoid return NaN and negative predictions.\n",
    "\n",
    "# # Fit ALS model to training data\n",
    "predicted_model = als.fit(training)\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = predicted_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName='rmse',labelCol='stars',\n",
    "                               predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root_Mean_Square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-bronze",
   "metadata": {},
   "source": [
    "#### 4. Add param_grid and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "athletic-integral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.3926480352111519\n",
      "***Best Model***\n",
      "   Rank: 40\n",
      "   maxIter: 20\n",
      "   regParam: 0.1\n",
      "CPU times: user 1.98 s, sys: 1.83 s, total: 3.81 s\n",
      "Wall time: 52min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = ParamGridBuilder().addGrid(als.rank,[30,35,40])\\\n",
    "             .addGrid(als.maxIter,[10,15,20])\\\n",
    "             .addGrid(als.regParam,[0.01,0.05,0.1])\\\n",
    "             .build()\n",
    "# Tuning parameters:\n",
    "#(1)rank: the rank of the U and P matrices\n",
    "#(2)Max iterations which tell spark how many times to alternate between U and P when minimizing the error\n",
    "#(3)regularization parameter: to prevent ALS from overfitting to the data\n",
    "# Define evaluator as RMSE\n",
    "evaluator = RegressionEvaluator(metricName='rmse',labelCol='stars',\n",
    "                               predictionCol='prediction')\n",
    "\n",
    "# Build cross validation using TrainValidationSplit\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator = als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator       \n",
    ")\n",
    "\n",
    "# Fit ALS model to training data\n",
    "model = tvs.fit(training)\n",
    "\n",
    "# Extract best model from the tuning exercise using ParamGridBuilder\n",
    "best_model = model.bestModel\n",
    "\n",
    "# Generate preditions and evaluate using RMSE\n",
    "predictions2 = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions2)\n",
    "\n",
    "# Print evaluation metrics \n",
    "print(\"RMSE = \" + str(rmse))\n",
    "print(\"***Best Model***\")\n",
    "print(\"   Rank:\",best_model.rank)\n",
    "print(\"   maxIter:\",best_model._java_obj.parent().getMaxIter())\n",
    "print(\"   regParam:\",best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-vector",
   "metadata": {},
   "source": [
    "### Step 3: Results\n",
    "#### 1. Predictions: \n",
    "     we could clearly see the comparation between real star and predicted star, although the rmse is high, it still could reflect users' preference to some degree.\n",
    "#### 2. Recommendations\n",
    "     Give each user 10 recommendations based on ranked predicted ratings.\n",
    "#### 3. Take usr_id= 0y8ORuC2X1i1UF6SG1hlkQ as an example\n",
    "     Because the original format of business_id and user_id are object not integer, so the step that we transform id between object type and interger type is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-crawford",
   "metadata": {},
   "source": [
    "#### 1. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "communist-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_all = best_model.transform(ALS_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "armed-newport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----+----------+\n",
      "|user_idx|business_idx|stars|prediction|\n",
      "+--------+------------+-----+----------+\n",
      "|       2|        4599|  4.0| 2.2479887|\n",
      "|       2|        2454|  4.0| 2.8458648|\n",
      "|       2|        4340|  4.0| 3.6926274|\n",
      "|       2|        8490|  4.0|  4.271734|\n",
      "|       6|        6320|  3.0| 2.6394508|\n",
      "+--------+------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.sort('user_idx','prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-granny",
   "metadata": {},
   "source": [
    "#### 2. Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "minimal-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|user_idx|     recommendations|\n",
      "+--------+--------------------+\n",
      "|     463|[[8947, 5.754446]...|\n",
      "|     471|[[1858, 4.326974]...|\n",
      "|     496|[[901, 3.9129672]...|\n",
      "|     833|[[8763, 5.55471],...|\n",
      "|    1088|[[6931, 5.4667664...|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 22 ms, sys: 8.76 ms, total: 30.8 ms\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate top 10 item recommendations for each user\n",
    "recommendations = best_model.recommendForAllUsers(10)\n",
    "recommendations.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addressed-passing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[business_idx: array<int>, rating: array<float>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ’rating‘ is the inner name in ALS Model, representing predicted rates not named by us.\n",
    "recommendations.select(\"recommendations.business_idx\",\"recommendations.rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "focal-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 ms, sys: 3.1 ms, total: 6.62 ms\n",
      "Wall time: 37.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql.functions import explode,col\n",
    "\n",
    "recs = recommendations.withColumn(\"rec_exp\",explode(\"recommendations\"))\\\n",
    "           .select(\"user_idx\",col(\"rec_exp.business_idx\"),col(\"rec_exp.rating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "herbal-elevation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+---------+\n",
      "|user_idx|business_idx|   rating|\n",
      "+--------+------------+---------+\n",
      "|     463|        8947| 5.754446|\n",
      "|     463|        8763|5.6977024|\n",
      "|     463|        7109| 5.681104|\n",
      "|     463|        8441| 5.653909|\n",
      "|     463|        8517|5.6490293|\n",
      "|     463|        1153|5.6353283|\n",
      "|     463|        2465| 5.630769|\n",
      "|     463|        9104| 5.629904|\n",
      "|     463|        2311|5.6221247|\n",
      "|     463|        1815|5.6167316|\n",
      "|     471|        1858| 4.326974|\n",
      "+--------+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recs.limit(11).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-record",
   "metadata": {},
   "source": [
    "#### 3. Take usr_id= 0y8ORuC2X1i1UF6SG1hlkQ as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "operating-parcel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = int(ALS_df.where(fn.col('user_id')== \"0y8ORuC2X1i1UF6SG1hlkQ\")\\\n",
    "            .toPandas()[\"user_idx\"][:1])\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "compound-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|business_idx|   rating|\n",
      "+------------+---------+\n",
      "|        8763|4.9332237|\n",
      "|        1748| 4.877681|\n",
      "|        2885| 4.877142|\n",
      "|        7494|4.8453774|\n",
      "|        3890|4.8261304|\n",
      "|           1| 4.785572|\n",
      "|        6492| 4.616911|\n",
      "|        4658|4.6011395|\n",
      "|        2567| 4.600248|\n",
      "|        7687|4.5992465|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the list of 10 recommendations business and their ratings\n",
    "business_idx = recs.where(fn.col('user_idx')==idx).select(\"business_idx\",\"rating\")    \n",
    "business_idx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "restricted-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+--------------------+\n",
      "|business_idx|   rating|         business_id|\n",
      "+------------+---------+--------------------+\n",
      "|           1| 4.785572|--9e1ONYQuAa-CB_R...|\n",
      "|        3890|4.8261304|a9ncRGtg3iWBpQmhp...|\n",
      "|        2885| 4.877142|80J9QfTbDYBk88rhd...|\n",
      "|        1748| 4.877681|-CQokjildrY7UZezX...|\n",
      "|        4658|4.6011395|oQvw4iamSyIm_Oi0o...|\n",
      "|        2567| 4.600248|cV95g6PN0RcTy0qDv...|\n",
      "|        7494|4.8453774|R6CvLpMoDEGQ7QApf...|\n",
      "|        7687|4.5992465|PmTirgprG7Lp9SH79...|\n",
      "|        6492| 4.616911|BBbYxS_CC0R8xyGi6...|\n",
      "|        8763|4.9332237|TBSuWtC0EyH2iDbq5...|\n",
      "+------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business_resc = business_idx.join(business_id_idx,on=\"business_idx\")\n",
    "business_resc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-conflict",
   "metadata": {},
   "source": [
    "#### This result shows the most recommended from user_id = 0y8ORuC2X1i1UF6SG1hlkQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "greatest-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------+------------+-----+---------+\n",
      "|         business_id|business_idx|  rating|review_count|state|     city|\n",
      "+--------------------+------------+--------+------------+-----+---------+\n",
      "|--9e1ONYQuAa-CB_R...|           1|4.785572|        1759|   NV|Las Vegas|\n",
      "+--------------------+------------+--------+------------+-----+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "CPU times: user 18.6 ms, sys: 24.9 ms, total: 43.5 ms\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# join the businessdf to return some extra information except business_id\n",
    "## Attention: I didn't select name and category and the business_df just have review_count/state/city\n",
    "## It will spend a long time to run them from the begining so I quit.\n",
    "\n",
    "\n",
    "resc_list = business_resc.join(businessdf,on = \"business_id\")\n",
    "resc_list.show(1)\n",
    "\n",
    "# This result shows the most recommended from user_id = 0y8ORuC2X1i1UF6SG1hlkQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-departure",
   "metadata": {},
   "source": [
    "### Conclusion for ALS :\n",
    "#### 1. This is an explicit problem:\n",
    "      Explicit problem:using explicit rating(such as rating a business from one to five stars), easier to predict but put the responsibility of data collection on the user;\n",
    "      Implicit problem:suitable to collect in large quantities without any extra effort on the part of the user, more difficult to work with.\n",
    "#### 2. Sparse Matrix\n",
    "     Although ALS is great to deal with sparse matrix, the more data, the better performance. In our model, we select the same city, select business and user whose number ratings is bigger than a specific number.\n",
    "#### 3. Limitation\n",
    "    (1）Cannot recommend to new users before they don't give any ratings\n",
    "    (2) Due to the Yelp data from official website, the categories are not clealy, this model cannot recommend slimilar business.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
